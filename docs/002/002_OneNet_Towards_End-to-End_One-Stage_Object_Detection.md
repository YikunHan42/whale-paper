# OneNet: Towards End-to-End One-Stage Object Detection

# OneNet： 实现端到端的单级物体检测

## 背景介绍：

物体检测是计算机视觉领域的一个重要任务，它可以在许多应用中发挥关键作用。然而，迄今为止，端到端单级物体检测一直处于落后状态。传统的单级检测器在标签分配中仅使用位置成本，这导致在推理过程中出现冗余的方框，需要使用非最大抑制（NMS）进行后处理。

为了解决这个问题，研究人员提出了一种最小成本分配法，以消除NMS并实现端到端检测。这种方法将分类成本和定位成本的总和作为成本，对于每个地面实况框，只有一个成本最小的样本被分配为正样本，其他样本都被分配为负样本。通过使用最小成本分配法进行训练，研究人员设计了一个名为OneNet的检测器，该检测器可以避免产生重复的方框，从而成为端到端的检测器。

OneNet具有全卷积和端到端训练的优点，不需要RoI操作或Attention交互。标签分配基于最小成本，而不是手工制作的启发式规则或复杂的双匹配。在推理过程中不需要任何后处理，如NMS或最大池化，从而提供了高效的目标检测。

通过在COCO数据集上进行实验，OneNet使用ResNet-50达到35.0 AP/80 FPS，使用ResNet-101达到37.7 AP/50 FPS。研究人员认为，使用更大的图像尺寸和更复杂的骨干网可以进一步提高检测精度，但推理速度会相应延迟。他们的方法旨在成为端到端单级对象检测的有效基准，因此所报告的性能是准确性和速度之间的权衡。

## 动机：

本文讨论了现有的单级对象检测器在标签分配中仅使用位置成本的问题，并提出了最小成本分配法来解决这个问题。传统的标签分配方法忽视了分类成本，导致推理中出现冗余方框，需要使用非极大值抑制（NMS）进行后处理。

研究人员认为，物体检测是一个包含分类和定位的多重任务，仅通过定位成本选择正样本可以最大限度地为定位任务做出贡献，但无法确保最优分类。最佳的解决方案是每个物体只有一个预测结果。然而，如果只使用定位成本进行训练，分类分支就会被迫输出近似解，即一个对象有多个预测结果。

为了解决这个问题，本文提出了最小成本分配法。该方法通过增加分类成本来消除NMS的需求，实现了端到端的检测。通过综合考虑位置成本和分类成本，最小成本分配法可以更准确地选择正样本，并确保每个物体只有一个预测结果。这种方法可以提高检测器的性能和效率。

## 模型架构、方法： 

![Image text](https://github.com/datawhalechina/whale-paper/blob/master/docs/002/images/ch01_workflows.png)

**OneNet 的流程。对于一幅 H × W ×3 的输入图像，骨干网络生成 H4 × W 4 ×C 的特征图，头部网络生成 H4 × W 4 ×K 的分类预测（其中 K 为类别数）和 H4 × W 4 × 4 的回归预测，最终输出为直接的前 k（例如 100）个评分框。**

OneNet是一种基本的全卷积单级检测器，它不需要任何后置程序（如非极大值抑制）。该模型的架构包括骨干网和头部。

骨干网是一个自下而上再自上而下的结构。自下而上的部分使用ResNet结构生成多尺度特征图。自顶向下的部分使用带有横向连接的特征金字塔网络（FPN）生成最终的物体识别特征图。输出特征图的形状为H/4 × W/4 × C，其中H和W分别是输入图像的高度和宽度。

头部通过两个平行卷积层对特征图H/4×W/4的每个网格点进行分类和定位。分类层预测每个网格点出现物体的概率，定位层预测每个网格点到地面实况框的4个边界的偏移量。

在训练过程中，使用最小成本分配法进行标签分配。该方法将成本定义为样本和地面实况之间的分类成本和定位成本的总和。对于每个物体的地面实况，只分配一个成本最低的样本作为正样本，其他样本都是负样本。训练损失由焦点损失、L1损失和GIoU损失组成。

在推理过程中，模型直接输出top-k（例如100）评分框，没有使用任何后置程序，如非极大值抑制或最大池化操作。

## 实验分析： 

### 实验细节

实验使用了对象检测任务的标准指标。所有模型都在COCO train2017数据集上进行训练（约118,000张图像），并在val2017数据集（5,000张图像）上进行评估。

优化器采用了AdamW，并设置了权重衰减为0.0001。每个批次的大小为64张图像，使用了8个英伟达V100 GPU进行训练。单头训练的初始学习率为5×10^-5，多头训练的初始学习率为1×10^-4。默认的训练计划是进行270,000次迭代，学习率在第210,000次和第250,000次迭代时分别除以10。

实验中使用的骨干网络是ResNet-50，并使用在ImageNet上预训练的权重进行初始化。根据方法[2, 42, 31]，设置了λcls=2，λL1=5，λgiou=2。数据增强包括对输入图像大小进行随机水平尺度抖动，使最短边至少为416像素，最长边最多为512像素。在推理过程中，默认图像大小为最短边512像素，最长边最多为853像素。在推理过程中，选择得分最高的100个边界框作为最终输出。

### 正样品的可视化

OneNet采用最小成本分配，考虑了分类成本和位置成本，将正样本分配给物体中更具区分度的区域，例如人体内部、斑马的头部。这样的选择对分类更有用，并且不会影响框回归。OneNet的正样本选择在总体上更为优秀。

### 消融研究

- 标签分配：实验结果表明，分类成本是去除非极大值抑制（NMS）的关键。没有分类成本时，模型会产生高置信度得分的冗余方框，需要使用NMS进行后处理。增加分类成本可以减少重复的方框，提高端到端检测器的性能。
- 训练时间表：训练时间越长，检测准确率越高，但耗时也越长。在实验中，从144个训练周期开始，检测准确率随着训练周期的增加而降低。因此，选择144个训练周期作为基准配置，以在检测准确率和训练时间之间取得平衡。
- 多头训练：简单提高学习率会降低检测精度。多头训练策略可以使模型从更大的学习率中获益，提高检测精度。然而，多头训练会降低推理速度，但在推理过程中没有引入额外的计算成本。
- 图像大小：图像大小对检测精度和推理速度有影响。较大的图像尺寸可以提高检测精度，但推理速度会变慢。图像尺寸的选择需要在检测精度和推理速度之间进行权衡。

### 与CenterNet的比较

OneNet 可以看作是用最小成本赋值取代了 CenterNet 中原有的标签赋值策略。OneNet 在检测精度和推理速度上都达到了与 CenterNet 相当的性能。

### 稀疏检测器中的标签分配

分类成本对稀疏检测器中 NMS 的去除也起着至关重要的作用。在没有分类成本的情况下，NMS 能显著提高性能。而增加分类成本则消除了 NMS 的必要性。稀疏检测器的实验结果与密集检测器相似。因此，论文认为成本分类是稀疏检测器和密集检测器端到端目标检测器的核心。

### 讨论

以往的方法在标签分配和网络优化目标之间存在偏差。物体检测器的优化目标通常是分类成本和定位成本的总和。然而，在一对一的盒分配和点分配中，正样本的选择只是为了最小化定位成本，例如盒IoU或点距离。这种情况下，所选的正样本可能无法最小化分类成本，特别是对于形状或姿势不规则的物体。换句话说，可能存在另一个潜在的正样本，可以为最小总成本做出贡献，但被错误地作为负样本处理。结果，网络被训练成了次优状态，将真正的正样本和被选中的正样本都归类为高分。在推理过程中，预测多余的阳性结果是合理的。

相反，一对一最小成本分配法确保所选的正样本具有最低的总成本（分类和回归），而其他样本的成本都不会更低。这样，网络的训练更加有效，并最终优化到理想状态，即每个对象都有一个预测结果。

## 总结： 

本文提出了一种最小成本分配法，通过增加分类成本来消除NMS，并实现了端到端的单级物体检测。实验结果表明，使用最小成本分配法进行训练的OneNet模型在COCO数据集上取得了良好的性能。这项工作启发人们重新思考物体检测中的标签分配，并为下一代物体检测器的发展提供了新的思路。